

layer 재구현
layers = [conv, relu, pool]
for layer:
	if layer.name.startwith("conv")
		nn.init....

forward:
	for


vals, inds = max(tensor)
mask = vals > 0.4
new_tensor = tensor[inds] * mask

inds = sort(tensor)
inds[:, :100]



--- 9.1
distribute_over_Feature map 함수
- bbox2d padding 제거후 feature로 입력 


label_and_sample_proposals()
	여기서 나온 instance_per_image['proposal_boxes']로 다시 gt와 매칭하여
	proposal 기준으로 정렬된 gt 만들기 (loss factory에서)

나머지 loss들을 정렬된 gt로 다시 계산

logger에서 val 모드일때만 nms 하고
nms 결과와 gt 매칭하여 true positive 개수 세기
-> history에 grtr, pred, trpo, recall, precision 추가



loggin loss 종류별로 저장


--- 8.25
- rpn: 2000개에서 pos는 다 포함, neg, ignore 이런건 어떻게 샘플링하는지
	- rpn proposal pos, neg 구분?
- head 출력 pos, neg 구분?

- train
	- pos + neg: 어디까지 pos 어디부터 neg ??
- test
	- pos만 출력
- 그림확인
	- train: pos only, neg only, gt
	- test: pos only, gt

- log: epoch별 loss 종류별로 평균치 로깅
- visual log: box 이미지로 만들어서 저장


--- 8.12
architecture.preprocess 에서
input의 image 제외한 나머지 이미지 단위로 쪼개서 list에 담기





--- 8.10
build_model
	raise customerror name이 없는 경우 에러내기 o
	backbone_factory 쪼개기 o
	말단 함수에 입력, 출력 타입 shape 의미 정리


convert_bev
get categories from config o


a2d2_trim_empty.py
a2d2 annotation 있는지 확인해서
annotation 없는 것 bev 이미지 삭제하기


device를 config에서 한번에 바꾸기


head는 batch 단위를 for문으로 돌리기 o




--- 8.5
loader: 박스 잘 그려지게
backbone, neck, rpn, head 순서대로 구현하고
	각각에 랜덤텐서 넣어서 원하는 shape의 출력 나오는지 확인
model factory, architecture 구현
loss factory, loss pool 구현
train_val을 pytorch로 변환

